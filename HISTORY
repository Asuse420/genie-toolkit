0.4.0-beta.1
============

Contextual support [#57, #62]:
* Added API to predict based on context.
* Added contextual templates for follow ups, incrementally adding filters, and
  answering slot-filling questions.
* Contextual sentence generation now runs in parallel using multiple threads.
  This requires a version of node compiled with worker support.
* Slot-filling answer in the templates use `bookkeeping(answer())` forms instead
  of generating new programs with the parameter slot-filled.
* Contextual evaluation now tracks "raw" string answers correctly.
* The `sample` and `mturk-validate` commands can now operate in contextual mode,
  to paraphrase contextual datasets.
* New command line tool `manual-annotate-dialog` to interactively annotate dialog
  datasets, while tracking context and answers correctly.
* New command line tool `typecheck` to typecheck a dataset, and optionally interactively
  correct it. The tool is mostly useful when the Thingpedia signatures change.
* Added MTurk template for contextual paraphrasing.

Question-Answering support [#61, #65]:
* The templates now include programs with projections, and the projections are
  preserved.
* Templates now honor the new `#[unique]` parameter annotation in ThingTalk.
* Added support for different grammatical forms of parameter `#_[canonical]` annotation.
* Added experimental templates for "who" questions, based on Wikidata.
* Added several new flags to the templates: `timer`, `projection`, `undefined_filter`,
  `projection_with_filter`, `extended_timers`.

General enhancements:
* The tokenizer client was updated to pass the full locale tag. This requires a recent
  version of almond-tokenizer, and enables distinguishing Simplified and Traditional
  Chinese [#70].
* Templates can now be packed in a self-contained ZIP file, suitable to upload
  to an instance of almond-cloud with enabled luinet. This allows one-click
  generation, training & deployment of Genie/LUInet models [#67].
* Added experimental templates for richer timers. These templates are behind a flag,
  `extended_timers`. [Ricky Grannis-Vu, #66].
* All commands now expect a `thingpedia.tt` file instead of a `thingpedia.json`
  file. The `download-snapshot` command has been updated to download the snapshot
  in ThingTalk format. Entities must be provided separately to the commands that
  need them [#58].
* Augmentation and generation now can track progress, and show a progress bar
  when called without debugging from the command line.
* Added parameter expansion for LOCATION, which soon will not be preprocessed by
  almond-tokenizer [#54].
* Added a new augmentation pass for commands that use a single device, which are
  prefixed with the device name, like in Alexa [#55].
* Fixed location of Los Angeles in the default constant file.
* Fixed parameter expansion to handle joins correctly [#69].
* Fixed support for primitive templates that include projections, aggregations
  and other complex ThingTalk operators [#68].
* Updated dependencies [#56, #59, #60, #63, #71, #79].

0.3.3
=====

* Fix tokenizer ignoring the expected value and not tokenizing locations correctly
  when given as answers

0.3.2
=====

* Fixed construct templates for location after get_gps was moved to @builtin

0.3.1
=====

* Fixed replacing parameters of bookkeeping commands

0.3.0
=====

* Added templates for the ThingTalk bookkeeping language, which includes
  commands such as "yes", "no", "more", "back", etc. [#42]
* Added a tool to preprocess datasets [#40]
* Experimental support for contextual commands (commands whose meaning
  changes based on the previously issued commands) [#5, #6, #43, #44]
* Improved templates for Chinese [#39]
* Added enum translation for Chinese [#35]
* Improved documentation for Internationalization [#40]
* Misc bug fixes [#41, #45, #46]
* Updated dependencies

Contributors in this release:
- Elvis Yu-Jing Lin
- Johnny Hsu

0.2.1
=====

* Pinned dependency `mmap-io` down to a functioning version.
* Fixed `train` command.

0.2.0
=====

* Added support for Simplified and Traditional Chinese. This support is experimental,
  incomplete, and might change in the future.
* Added commands to evaluate the dataset against a running server, or against a file
  of predictions, and compute error analysis
* Added a command to annotate a file by hand; this command brings up an interactive
  command-line UI
* Added command to generate a cheatsheet in PDF form, and mturk pages to collect
  cheatsheet data
* Added decanlp training and evaluation backend
* The tokenization client is now part of the public API
* New construct templates: placeholders ("some X", "something", "some person", etc.)
* Policies, aggregations and remote command templates are now hidden behind a flag
* The parameter replacement augmentation step now requires more fallback parameter
  lists, and will optionally use them even if a more specific list is available
* Synthetic generation and augmentation hyperparameters have been tuned
* Fixed evaluation sets generated by DatasetSplitter [#9]
* Updated dependencies

0.1.0
=====

* First public release
